prior_overdis <- list(prior = "exp", param = prior_overdis)
######################################################################
####### 2. Running model for each country at each age-group: #########
######################################################################
selected_prov <- unique(canada_weekly$province)
selected_ages <- unique(canada_weekly$age)
model_result_all <- data.frame()
selected_prov
prov = "QC"
selected_ages
Age = "Age at time of death, 0 to 44 years"
selected_CA <- canada_weekly %>% filter(province == prov & age == Age) %>% arrange(date)
selected_CA
selected_CA$date
selected_CA <- canada_weekly %>% filter(province == prov & age == Age) %>% arrange(date)
selected_CA <- na.omit(selected_CA)
diff(range(selected_CA$year))
k_IWP <- 100
k_sGP <- 40
model_list <- fit_mod_IWP_sGP(canada_death = selected_CA, prior_IWP = prior_SD1, prior_sGP = prior_SD2, prior_overdis = prior_overdis, k_IWP = k_IWP, k_sGP = k_sGP, prov = prov, Age = Age, m = m)
source("~/Desktop/mortality/Canada/v4_update/script_server.R", echo=TRUE)
source("~/Desktop/mortality/Canada/v4_update/script_server.R", echo=TRUE)
.libPaths(c("~/lib", .libPaths()))
require(tidyverse)
require(aghq)
require(TMB)
require(Matrix)
require(lubridate)
require(ISOweek)
require(BayesGP)
source(file = "function.R")
load(file = "final_data.rda")
canada_weekly <- final_data %>% arrange(date)
canada_weekly$date <- as.Date(canada_weekly$date)
canada_weekly$year <- year(canada_weekly$date)
####################################################
####### 1. Setting up the prior of SD: #############
####################################################
p = 2; d1 = 5 ## 5 years PSD for IWP-2
a = 2*pi; d2 = 1 ## 1 year PSD for the aggregated sGP
m = 4 ## Include its four harmonics
prior_overdis <- list(u = 0.1, alpha = 0.01)
prior_PSD1 <- list(u = 0.1, alpha = 0.01)
prior_PSD2 <- list(u = 0.1, alpha = 0.01)
prior_SD1 <- prior_conversion_iwp(d = d1, prior = prior_PSD1, p = p)
prior_SD2 <- prior_conversion_sgp(d = d2, prior = prior_PSD2, a = a, m = m)
prior_SD1 <- list(prior = "exp", param = prior_SD1)
prior_SD2 <- list(prior = "exp", param = prior_SD2)
prior_overdis <- list(prior = "exp", param = prior_overdis)
######################################################################
####### 2. Running model for each country at each age-group: #########
######################################################################
selected_prov <- unique(canada_weekly$province)
selected_ages <- unique(canada_weekly$age)
model_result_all <- data.frame()
prov = "ON"
Age = selected_ages[1]
selected_CA <- canada_weekly %>% filter(province == prov & age == Age) %>% arrange(date)
selected_CA <- na.omit(selected_CA)
k_IWP <- 100
k_sGP <- 40
model_list <- fit_mod_IWP_sGP(canada_death = selected_CA, prior_IWP = prior_SD1, prior_sGP = prior_SD2, prior_overdis = prior_overdis, k_IWP = k_IWP, k_sGP = k_sGP, prov = prov, Age = Age, m = m)
model_pred <- pred_mortality_obs(model_list = model_list, refined_pred = model_list$x_full)
BayesGP:::Compute_Q_sB
pred_mortality_obs
.libPaths(c("~/lib", .libPaths()))
require(tidyverse)
require(aghq)
require(TMB)
require(Matrix)
require(lubridate)
require(ISOweek)
require(BayesGP)
source(file = "function.R")
plot(lynx)
plot(lynx, type = "o")
plot(lynx, type = "p")
plot(lynx, type = "o")
plot(lynx, type = "o", log = "y")
plot(lynx, type = "o", log = "y", axis.cex = 2)
plot(lynx, type = "o", log = "y", cex = 2)
plot(lynx, type = "o", log = "y", cex = 1)
plot(lynx, type = "p", log = "y", cex = 1)
plot(lynx, type = "p", log = "y", cex = 1)
plot(lynx, type = "o", log = "y", cex = 1)
plot(lynx, type = "o", log = "y", cex.lab = 1)
plot(lynx, type = "o", log = "y", cex.lab = 2)
plot(lynx, type = "o", log = "y", cex.lab = 3)
plot(lynx, type = "o", log = "y", cex.lab = 10)
plot(lynx, type = "o", log = "y", cex.lab = 1.5, cex.axis = 2)
plot(lynx, type = "o", log = "y", cex.lab = 1.5, cex.axis = 2)
lynx
rescale <- function(x){
2*x/10
}
rescale(10)
rescale(9)
rescale(10 - 0.75)
rescale(10 - 3)
rescale(10 - 0.5)
rescale(10 - 0.75 - 0.5 - 1 - 0.5 - 0.5 - 0.5)
rescale(10 - 0.5)
rescale(10 - 1.5 - 1 - 0.5 - 0.5 - 0.5)
rescale <- function(x){
x*2/5
}
rescale(5)
scale <- function(x) {
(x*2)/5
}
scale(5 - 0.25-0.25-0.25-0.25-1-1-0.25)
scale(4)
scale(5 - 0.25 - 0.25 - 0. 25 - 0.25 - p1q6 - 0.25 - 0.25)
p1q6 <- 1
scale(5 - 0.25 - 0.25 - 0. 25 - 0.25 - p1q6 - 0.25 - 0.25)
scale(5 - 0.25 - 0.25 - 0.25 - 0.25 - p1q6 - 0.25 - 0.25)
scale(5 - 1 - 0.5)
scale(5 - 3 - 0.5)
scale(5 - 1 - 0.5)
scale(0.25)
x <- seq(from = 0, to = 1, length.out = 101)
plot(x, matern.covariance(abs(x - 0.5), kappa = 10, nu = 1 / 5, sigma = 1),
type = "l", ylab = "C(h)", xlab = "h"
)
library(rSPDE)
install.packages("rSPDE")
library(rSPDE)
library(rSPDE)
x <- seq(from = 0, to = 1, length.out = 101)
plot(x, matern.covariance(abs(x - 0.5), kappa = 10, nu = 1 / 5, sigma = 1),
type = "l", ylab = "C(h)", xlab = "h"
)
?matern.covariance
h <- 0.1
n <- 1 / h
C <- matern.covariance(abs(x - 0.5), kappa = 10, nu = 1 / 5, sigma = 1)
C <- matrix(C, nrow = length(x), ncol = length(x))
image(C, col = heat.colors(100), xlab = "i", ylab = "j")
C
matern_cov <- function(x, kappa, nu, sigma) {
C <- matern.covariance(x, kappa = kappa, nu = nu, sigma = sigma)
C <- matrix(C, nrow = length(x), ncol = length(x))
return(C)
}
x <- seq(from = 0, to = 1, length.out = 5)
C <- matern_cov(abs(x - 0.5), kappa = 10, nu = 1 / 5, sigma = 1)
image(C, col = heat.colors(100), xlab = "i", ylab = "j")
C
C
h <- 0.1
n <- 1 / h
C <- matern.covariance(abs(x - 0.5), kappa = 10, nu = 1 / 5, sigma = 1)
C <- matrix(C, nrow = length(x), ncol = length(x))
image(C, col = heat.colors(100), xlab = "i", ylab = "j")
C
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:j) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 1 / 5, sigma = 1)
}
}
M <- forceSymmetric(M)
return(M)
}
create_matern_mat(0.1)
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:i) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 1 / 5, sigma = 1)
}
}
M <- forceSymmetric(M)
return(M)
}
create_matern_mat(0.1)
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:i) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 1 / 5, sigma = 1)
}
}
M <- forceSymmetric(M, upper = TRUE)
return(M)
}
create_matern_mat(0.1)
?forceSymmetric
## Create the covariance matrix of matern, when spacing is h:
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:i) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 1 / 5, sigma = 1)
}
}
M <- forceSymmetric(M, uplo = "U")
return(M)
}
create_matern_mat(0.1)
## Create the covariance matrix of matern, when spacing is h:
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:i) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 1 / 5, sigma = 1)
}
}
# M <- forceSymmetric(M, uplo = "U")
return(M)
}
create_matern_mat(0.1)
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:i) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 1 / 5, sigma = 1)
}
}
M <- forceSymmetric(M, uplo = "L")
return(M)
}
create_matern_mat(0.1)
eigen(create_matern_mat(0.1), only.values = T)
min(eigen(create_matern_mat(0.1), only.values = T)$values)
min(eigen(create_matern_mat(0.2), only.values = T)$values)
plot(seq(0.01, 0.1, 0.01), sapply(seq(0.01, 0.1, 0.01), function(x) min(eigen(create_matern_mat(x), only.values = T)$values)), type = "l", ylab = "min(eigenvalue)", xlab = "h")
plot(seq(0.001, 1, 0.001), sapply(seq(0.001, 0.1, 0.001), function(x) min(eigen(create_matern_mat(x), only.values = T)$values)), type = "l", ylab = "min(eigenvalue)", xlab = "h")
plot(seq(0.001, 1, 0.001), sapply(seq(0.001, 1, 0.001), function(x) min(eigen(create_matern_mat(x), only.values = T)$values)), type = "l", ylab = "min(eigenvalue)", xlab = "h")
## Create the covariance matrix of matern, when spacing is h:
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:i) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 3, sigma = 1)
}
}
M <- forceSymmetric(M, uplo = "L")
return(M)
}
## Plot the smallest eigenvalue of the covariance matrix of matern, when spacing is h:
plot(seq(0.001, 1, 0.001), sapply(seq(0.001, 1, 0.001), function(x) min(eigen(create_matern_mat(x), only.values = T)$values)), type = "l", ylab = "min(eigenvalue)", xlab = "h")
## Create the covariance matrix of matern, when spacing is h:
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:i) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 2, sigma = 1)
}
}
M <- forceSymmetric(M, uplo = "L")
return(M)
}
## Plot the smallest eigenvalue of the covariance matrix of matern, when spacing is h:
plot(seq(0.001, 1, 0.001), sapply(seq(0.001, 1, 0.001), function(x) min(eigen(create_matern_mat(x), only.values = T)$values)), type = "l", ylab = "min(eigenvalue)", xlab = "h")
## Create the covariance matrix of matern, when spacing is h:
create_matern_mat <- function(h, I = 1){
vec <- seq(from = 0, to = I, by = h)
n <- length(vec)
M <- matrix(0, n, n)
for (i in 1:nrow(M)) {
for (j in 1:i) {
M[i, j] <- matern.covariance(abs(vec[i] - vec[j]), kappa = 10, nu = 4, sigma = 1)
}
}
M <- forceSymmetric(M, uplo = "L")
return(M)
}
## Plot the smallest eigenvalue of the covariance matrix of matern, when spacing is h:
plot(seq(0.001, 1, 0.001), sapply(seq(0.001, 1, 0.001), function(x) min(eigen(create_matern_mat(x), only.values = T)$values)), type = "l", ylab = "min(eigenvalue)", xlab = "h")
p1q0 + p1q1 + p1q2 + p1q3 + p1q4 + p1q5 + p1q6 + p1q7 + p1q8
p1q0 <- 0.2
p1q1 <- 0.2
p1q2 <- 0.2
p1q3 <- 0.2
p1q4 <- 0.2
p1q5 <- 0.4
p1q6 <- 0.4
p1q7 <- 0.1
p1q8 <- 0.1
## check the sum:
p1q0 + p1q1 + p1q2 + p1q3 + p1q4 + p1q5 + p1q6 + p1q7 + p1q8
2 - p1q2 - p1q3 - p1q4 - p1q5 - p1q6
2 - p1q2 - p1q3 - p1q5 - p1q6 - p1q7
2 - p1q0 - p1q1 - p1q2 - p1q5 - p1q6
2 - p1q0 - p1q1 - p1q2 - p1q5 - p1q6 - p1q7
setwd("~/Desktop/BOBI/BOSS_code/example1_co2")
.libPaths( c( .libPaths(), "~/./lib") )
#### PATH:
working_path <- getwd()
source_path <- paste0(working_path,"/source/")
figure_path <- paste0(working_path,"/figures/")
result_path <- paste0(working_path,"/results/")
source(file = paste0(source_path, "00_load.R"))
source(file = paste0(source_path, "bo_functions.R"))
### Read in the full data:
cUrl = paste0("http://scrippsco2.ucsd.edu/assets/data/atmospheric/",
"stations/flask_co2/daily/daily_flask_co2_mlo.csv")
cFile = basename(cUrl)
if (!file.exists(cFile)) download.file(cUrl, cFile)
co2s = read.table(cFile, header = FALSE, sep = ",",
skip = 69, stringsAsFactors = FALSE, col.names = c("day",
"time", "junk1", "junk2", "Nflasks", "quality",
"co2"))
co2s$date = strptime(paste(co2s$day, co2s$time), format = "%Y-%m-%d %H:%M",
tz = "UTC")
co2s$day = as.Date(co2s$date)
timeOrigin = as.Date("1960/03/30")
co2s$timeYears = round(as.numeric(co2s$day - timeOrigin)/365.25,
3)
co2s$dayInt = as.integer(co2s$day)
allDays = seq(from = min(co2s$day), to = max(co2s$day),
by = "7 day")
observed_dataset <- co2s %>% filter(!is.na(co2s$co2)) %>% dplyr::select(c("co2", "timeYears"))
observed_dataset$quality <- ifelse(co2s$quality > 0, 1, 0)
observed_dataset <- observed_dataset %>% filter(quality == 0)
### Create the covariate for trend and the 1-year seasonality
observed_dataset$t1 <- observed_dataset$timeYears
observed_dataset$t2 <- observed_dataset$timeYears
observed_dataset$t3 <- observed_dataset$timeYears
observed_dataset$t4 <- observed_dataset$timeYears
lower <- 2
upper <- 6
eval_once <- function(a){
### reduce the number of harmonic of 2*pi/a to just one. (previously two)
mod_once <- model_fit(formula = co2 ~ f(x = t1, model = "IWP", order = 2, sd.prior = list(param = 30, h = 10), k = 30, initial_location = median(observed_dataset$t1)) +
f(x = t2, model = "sGP", sd.prior = list(param = 1, h = 10), a = (2*pi), m = 2, k = 30) +
f(x = t3, model = "sGP", sd.prior = list(param = 1, h = 10), a = (2*pi/a), m = 1, k = 30),
data = observed_dataset,
control.family = list(sd.prior = list(param = 1)),
family = "Gaussian", aghq_k = 3)
mod_once$mod$normalized_posterior$lognormconst
}
begin_time <- Sys.time()
load("BO_result.rda")
data_to_smooth <- BO_result$result[order(BO_result$result$x), ]
plot(exp(y) ~ x_original, data_to_smooth, type = "o")
surrogate <- function(xvalue, data_to_smooth){
pp <- predict_gp(data = data_to_smooth, x_pred = xvalue, noise_var = 1e-6, choice_cov = square_exp_cov_generator(length_scale = BO_result$length_scale, signal_var = BO_result$signal_var))
pp$mean
}
integrate_aghq <- function(f, k = 100, startingvalue = 0){
ff <- list(fn = f, gr = function(x) numDeriv::grad(f, x), he = function(x) numDeriv::hessian(f, x))
aghq::aghq(ff = ff, k = k, startingvalue = startingvalue)$normalized_posterior$lognormconst
}
x <- seq(2.01, 5.99, by = 0.01)
y <- qnorm((x - lower)/(upper - lower))
ff <- list()
ff$fn <- function(y) as.numeric(surrogate(pnorm(y), data_to_smooth = data_to_smooth) + dnorm(y, log = TRUE))
fn_vals <- sapply(y, ff$fn)
plot(exp(fn_vals) ~ y, type = "l")
lognormal_const <- integrate_aghq(f = ff$fn, k = 10)
post_y <- data.frame(y = y, pos = exp(fn_vals - lognormal_const))
post_x <- data.frame(x = pnorm(post_y$y) * (upper - lower) + lower, post = (post_y$pos / dnorm(post_y$y))/(upper - lower) )
### Plot the posterior of alpha:
tikzDevice::tikz(file = paste0("co2_pi_alpha.tex"), width = 5, height = 5, standAlone = TRUE)
plot(post_x$post ~ post_x$x, type = "l", ylab = "Post",
xlab = expression(alpha) , cex.lab = 1.5, cex.axis = 1.5)
for(x_val in data_to_smooth$x_original) {
segments(x_val, -0.02, x_val, -0.05, col = "red")
}
dev.off()
system(paste0("pdflatex ", "co2_pi_alpha.tex"))
file.remove(paste0("co2_pi_alpha.aux"))
file.remove(paste0("co2_pi_alpha.log"))
file.remove(paste0("co2_pi_alpha.tex"))
### Plot the posterior of alpha:
tikzDevice::tikz(file = paste0("co2_pi_alpha.tex"), width = 5, height = 5, standAlone = TRUE)
plot(post_x$post ~ post_x$x, type = "l", ylab = "Post",
xlab = '$\\alpha$' , cex.lab = 1.5, cex.axis = 1.5)
for(x_val in data_to_smooth$x_original) {
segments(x_val, -0.02, x_val, -0.05, col = "red")
}
dev.off()
system(paste0("pdflatex ", "co2_pi_alpha.tex"))
file.remove(paste0("co2_pi_alpha.aux"))
file.remove(paste0("co2_pi_alpha.log"))
file.remove(paste0("co2_pi_alpha.tex"))
### Compute the HPD:
post_x$x <- round(post_x$x, digits = 2)
my_cdf <- cumsum(post_x$post * c(diff(post_x$x), 0))
my_cdf[which(post_x$x == 3.47)] - my_cdf[which(post_x$x == 3.11)]
plot(post_x$post ~ post_x$x, type = "l", ylab = "Post",
xlab = expression(alpha), cex.lab = 2.0, cex.axis = 2.0)
abline(v = 3.47, col = "purple")
abline(v = 3.11, col = "purple")
my_cdf[which(post_x$x == 3.82)] - my_cdf[which(post_x$x == 2.82)]
plot(post_x$post ~ post_x$x, type = "l", ylab = "Post",
xlab = expression(alpha), cex.lab = 2.0, cex.axis = 2.0)
abline(v = 3.82, col = "purple")
abline(v = 2.82, col = "purple")
### Approximate Quadrature rules from BOSS:
aghq_boss <- function(f, k = 100, data_to_smooth){
ff <- list(fn = f, gr = function(x) numDeriv::grad(f, x), he = function(x) numDeriv::hessian(f, x))
opt_result <- list(ff = ff, mode = qnorm(data_to_smooth$x[which.max(data_to_smooth$y)]))
opt_result$hessian = -matrix(ff$he(opt_result$mode))
aghq::aghq(ff = ff, k = k, optresults = opt_result, startingvalue = opt_result$mode)
}
aghq_boss_obj <- aghq_boss(f = ff$fn, k = 10, data_to_smooth)
nodes <- aghq_boss_obj[[1]]$grid$nodes
nodes_converted <- as.numeric(pnorm(nodes)*(upper - lower) + lower)
L <- as.numeric(sqrt(aghq_boss_obj$normalized_posterior$grid$features$C))
weights <- as.numeric(aghq_boss_obj[[1]]$nodesandweights$weights)
lambda <- weights * exp(aghq_boss_obj[[1]]$nodesandweights$logpost_normalized)
### Fit new models at these nodes:
fit_once <- function(a){
### reduce the number of harmonic of 2*pi/a to just one. (previously two)
mod_once <- model_fit(formula = co2 ~ f(x = t1, model = "IWP", order = 2, sd.prior = list(param = 30, h = 10), k = 30, initial_location = median(observed_dataset$t1)) +
f(x = t2, model = "sGP", sd.prior = list(param = 1, h = 10), a = (2*pi), m = 2, k = 30) +
f(x = t3, model = "sGP", sd.prior = list(param = 1, h = 10), a = (2*pi/a), m = 1, k = 30),
data = observed_dataset,
control.family = list(sd.prior = list(param = 1)),
family = "Gaussian", aghq_k = 3)
mod_once
}
set.seed(123)
### Inferring the latent field:
num_samples <- round(3000 * lambda, 0)
t1_samples <- data.frame(t = seq(0,62, by = 0.01))
t2_samples <- data.frame(t = seq(0,62, by = 0.01))
t3_samples <- data.frame(t = seq(0,62, by = 0.01))
for (i in 1:length(num_samples)) {
load(file = paste0("models/model_", i, ".rda"))
pred <- predict(mod, variable = "t1", only.samples = T, newdata = data.frame(t1 = seq(0,62, by = 0.01)))[,-1][,1:num_samples[i]]
t1_samples <- cbind(t1_samples, pred)
pred <- predict(mod, variable = "t2", only.samples = T, newdata = data.frame(t2 = seq(0,62, by = 0.01)))[,-1][,1:num_samples[i]]
t2_samples <- cbind(t2_samples, pred)
pred <- predict(mod, variable = "t3", only.samples = T, newdata = data.frame(t3 = seq(0,62, by = 0.01)))[,-1][,1:num_samples[i]]
t3_samples <- cbind(t3_samples, pred)
}
t1_summary <- extract_mean_interval_given_samps(t1_samples)
t2_summary <- extract_mean_interval_given_samps(t2_samples)
t3_summary <- extract_mean_interval_given_samps(t3_samples)
t_all_samples <- t1_samples + t2_samples + t3_samples
t_all_samples[,1] <- t1_samples[,1]
t_all_summary <- extract_mean_interval_given_samps(t_all_samples)
t_all_summary$time <- (t_all_summary$x * 365.25) + timeOrigin
plot(t_all_summary$q0.5 ~ t_all_summary$time, type = "l", lty = "solid", ylab = "CO2", xlab = "year")
lines(t_all_summary$q0.975 ~ t_all_summary$time, col = "red", lty = "dashed")
lines(t_all_summary$q0.025 ~ t_all_summary$time, col = "red", lty = "dashed")
plot(t_all_summary$q0.5 ~ t_all_summary$time, type = "l",
lty = "solid", ylab = "CO2", xlab = "year", cex.lab = 1.5, cex.axis = 1.5)
lines(t_all_summary$q0.975 ~ t_all_summary$time, col = "red", lty = "dashed")
lines(t_all_summary$q0.025 ~ t_all_summary$time, col = "red", lty = "dashed")
tikzDevice::tikz(file = paste0("co2_overall.tex"), width = 5, height = 5, standAlone = TRUE)
plot(t_all_summary$q0.5 ~ t_all_summary$time, type = "l",
lty = "solid", ylab = "CO2", xlab = "year", cex.lab = 1.5, cex.axis = 1.5)
lines(t_all_summary$q0.975 ~ t_all_summary$time, col = "red", lty = "dashed")
lines(t_all_summary$q0.025 ~ t_all_summary$time, col = "red", lty = "dashed")
dev.off()
system(paste0("pdflatex ", "co2_overall.tex"))
file.remove(paste0("co2_overall.aux"))
file.remove(paste0("co2_overall.log"))
file.remove(paste0("co2_overall.tex"))
t1_summary$time <- (t1_summary$x * 365.25) + timeOrigin
plot(t1_summary$q0.5 ~ t1_summary$time, type = "l", lty = "solid", ylab = "CO2", xlab = "year")
lines(t1_summary$q0.975 ~ t1_summary$time, col = "red", lty = "dashed")
lines(t1_summary$q0.025 ~ t1_summary$time, col = "red", lty = "dashed")
t1_summary$time <- (t1_summary$x * 365.25) + timeOrigin
plot(t1_summary$q0.5 ~ t1_summary$time, type = "l", lty = "solid", ylab = "CO2",
xlab = "year", cex.lab = 1.5, cex.axis = 1.5)
lines(t1_summary$q0.975 ~ t1_summary$time, col = "red", lty = "dashed")
lines(t1_summary$q0.025 ~ t1_summary$time, col = "red", lty = "dashed")
tikzDevice::tikz(file = paste0("co2_trend.tex"), width = 5, height = 5, standAlone = TRUE)
plot(t1_summary$q0.5 ~ t1_summary$time, type = "l", lty = "solid", ylab = "CO2",
xlab = "year", cex.lab = 1.5, cex.axis = 1.5)
lines(t1_summary$q0.975 ~ t1_summary$time, col = "red", lty = "dashed")
lines(t1_summary$q0.025 ~ t1_summary$time, col = "red", lty = "dashed")
dev.off()
system(paste0("pdflatex ", "co2_trend.tex"))
file.remove(paste0("co2_trend.aux"))
file.remove(paste0("co2_trend.log"))
file.remove(paste0("co2_trend.tex"))
ts_samples <- t2_samples + t3_samples
ts_samples[,1] <- t2_samples[,1]
ts_summary <- extract_mean_interval_given_samps(ts_samples)
ts_summary$time <- (ts_summary$x * 365.25) + timeOrigin
plot(ts_summary$q0.5 ~ ts_summary$time, type = "l", lty = "solid", ylab = "CO2", xlab = "year",
xlim = as.Date(c("1985-01-01","2000-01-01")), ylim = c(725, 740))
lines(ts_summary$q0.975 ~ ts_summary$time, col = "red", lty = "dashed")
lines(ts_summary$q0.025 ~ ts_summary$time, col = "red", lty = "dashed")
plot(ts_summary$q0.5 ~ ts_summary$time, type = "l", lty = "solid", ylab = "CO2", xlab = "year",
xlim = as.Date(c("1985-01-01","2000-01-01")), ylim = c(725, 740), cex.lab = 1.5, cex.axis = 1.5)
lines(ts_summary$q0.975 ~ ts_summary$time, col = "red", lty = "dashed")
lines(ts_summary$q0.025 ~ ts_summary$time, col = "red", lty = "dashed")
tikzDevice::tikz(file = paste0("co2_seasonal.tex"), width = 5, height = 5, standAlone = TRUE)
plot(ts_summary$q0.5 ~ ts_summary$time, type = "l", lty = "solid", ylab = "CO2", xlab = "year",
xlim = as.Date(c("1985-01-01","2000-01-01")), ylim = c(725, 740), cex.lab = 1.5, cex.axis = 1.5)
lines(ts_summary$q0.975 ~ ts_summary$time, col = "red", lty = "dashed")
lines(ts_summary$q0.025 ~ ts_summary$time, col = "red", lty = "dashed")
dev.off()
system(paste0("pdflatex ", "co2_seasonal.tex"))
file.remove(paste0("co2_seasonal.aux"))
file.remove(paste0("co2_seasonal.log"))
file.remove(paste0("co2_seasonal.tex"))
